{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sd_streets_ids.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google Drive via Google Colab"
      ],
      "metadata": {
        "id": "dIf-siSTXIHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R907Jerc49k",
        "outputId": "f79806be-3d16-4518-be8f-b1f62051f305"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read in the Data From GitHub Repository "
      ],
      "metadata": {
        "id": "_9xLhh4WXeDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('https://raw.githubusercontent.com/lshpaner/sd_streets/main/'\\\n",
        "                   +'data/oci_2015_datasd.csv')\n",
        "df2 = pd.read_csv('https://raw.githubusercontent.com/lshpaner/sd_streets/main/'\\\n",
        "                   +'data/sd_paving_datasd.csv')\n",
        "df3 = pd.read_csv('https://raw.githubusercontent.com/lshpaner/sd_streets/main/'\\\n",
        "                   +'data/traffic_counts_datasd.csv')\n",
        "df4 = pd.read_csv('https://raw.githubusercontent.com/lshpaner/sd_streets/main/'\\\n",
        "                   +'merged_data/sd_roads_dataframe.csv')"
      ],
      "metadata": {
        "id": "DZtUsts_cakf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect Columns of Dataframes"
      ],
      "metadata": {
        "id": "xQALJy-hXgHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('df1:', df1.columns, '\\n')\n",
        "print('df2:', df2.columns, '\\n')\n",
        "print('df3:', df3.columns, '\\n')\n",
        "print('df4:', df4.columns, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-Lq0w_6fd1v",
        "outputId": "e3f57d74-db98-44c2-f9da-0951f8f9c329"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df1: Index(['seg_id', 'oci', 'street', 'street_from', 'street_to', 'seg_length_ft',\n",
            "       'seg_width_ft', 'func_class', 'pvm_class', 'area_sq_ft', 'oci_desc',\n",
            "       'oci_wt'],\n",
            "      dtype='object') \n",
            "\n",
            "df2: Index(['pve_id', 'seg_id', 'project_id', 'title', 'project_manager',\n",
            "       'project_manager_phone', 'status', 'type', 'resident_engineer',\n",
            "       'address_street', 'street_from', 'street_to', 'seg_cd', 'length',\n",
            "       'width', 'date_moratorium', 'date_start', 'date_end', 'paving_miles'],\n",
            "      dtype='object') \n",
            "\n",
            "df3: Index(['id', 'street_name', 'limits', 'northbound_count', 'southbound_count',\n",
            "       'eastbound_count', 'westbound_count', 'total_count', 'file_no',\n",
            "       'date_count'],\n",
            "      dtype='object') \n",
            "\n",
            "df4: Index(['Unnamed: 0', 'oci', 'seg_length_ft', 'seg_width_ft', 'area_sq_ft',\n",
            "       'oci_wt', 'seg_cd', 'length', 'width', 'paving_miles', 'oci_cat',\n",
            "       'func_cat', 'pvm_cat', 'status_cat', 'day_diff'],\n",
            "      dtype='object') \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## San Diego Street Conditions Classification Report - Full Code"
      ],
      "metadata": {
        "id": "OIvt7wWRW-fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "from tabulate import tabulate\n",
        "\n",
        "df1 = pd.read_csv('https://raw.githubusercontent.com/lshpaner/sd_streets/main/'\\\n",
        "                   +'data/oci_2015_datasd.csv')\n",
        "df2 = pd.read_csv('https://raw.githubusercontent.com/lshpaner/sd_streets/main/'\\\n",
        "                   +'data/sd_paving_datasd.csv')\n",
        "df3 = pd.read_csv('https://raw.githubusercontent.com/lshpaner/sd_streets/main/'\\\n",
        "                   +'data/traffic_counts_datasd.csv')\n",
        "df4 = pd.read_csv('https://raw.githubusercontent.com/lshpaner/sd_streets/main/'\\\n",
        "                   +'merged_data/sd_roads_dataframe.csv')\n",
        "\n",
        "# create an empty log container \n",
        "log_txt = []\n",
        "\n",
        "names = ['Streets OCI', 'Street Repair Projects', \n",
        "         'Traffic Volumes', 'Merged Dataframe']\n",
        "dataframes = df1, df2, df3, df4\n",
        "\n",
        "header1 = ' '\n",
        "print(header1)\n",
        "log_txt.append(header1)\n",
        "\n",
        "# shape of merged df file\n",
        "header2 = 'Merged File'\n",
        "print(header2)\n",
        "log_txt.append(header2)\n",
        "header3 = 'No. of Rows in Merged File: ' + str(f\"{df4.shape[0]:,}\")\n",
        "print(header3)\n",
        "log_txt.append(header3)\n",
        "header4 = 'No. of Columns in Merged File: ' + str(f\"{df4.shape[1]:,}\")\n",
        "print(header4)\n",
        "log_txt.append(header4)\n",
        "header5 = ' '\n",
        "print(header5)\n",
        "log_txt.append(header5)\n",
        "\n",
        "# OCI file\n",
        "header6 = 'Streets Overall Condition Index (OCI)'\n",
        "print(header6)\n",
        "log_txt.append(header6)\n",
        "header7 = 'No. of Rows in OCI File: ' + str(f\"{df1.shape[0]:,}\")\n",
        "print(header7)\n",
        "log_txt.append(header7)\n",
        "header8 = 'No. of Columns in OCI File: ' + str(f\"{df1.shape[1]:,}\")\n",
        "print(header8)\n",
        "log_txt.append(header8)\n",
        "\n",
        "header9 = ' '\n",
        "print(header9)\n",
        "log_txt.append(header9)\n",
        "\n",
        "oci_id = df1.filter(like='_id').columns\n",
        "if df1[oci_id].columns.any():\n",
        "  df1_print = df1[oci_id].nunique().apply(lambda x : \"{:,}\".format(x))\n",
        "  df1_print = pd.DataFrame(df1_print)\n",
        "  df1_print.reset_index(inplace=True)\n",
        "  df1_print = df1_print.rename(columns={0: 'Distinct Count',\n",
        "                                           'index':'ID Columns'})\n",
        "  df1_tab = tabulate(df1_print, headers = 'keys', tablefmt = 'psql')\n",
        "  print(df1_tab)\n",
        "  log_txt.append(df1_tab)\n",
        "else:\n",
        "  df1_notab= 'Street OCI IDs DO NOT exist.'\n",
        "  print(df1_notab)\n",
        "  log_txt.append(df1_notab)\n",
        "\n",
        "header10 = ' '\n",
        "print(header10)\n",
        "log_txt.append(header10)\n",
        "\n",
        "# Street Repair Projects File\n",
        "header11 = 'Street Repair Projects'\n",
        "print(header11)\n",
        "log_txt.append(header11)\n",
        "header12 = 'No. of Rows in Street Repairs File: ' + str(f\"{df2.shape[0]:,}\")\n",
        "print(header12)\n",
        "log_txt.append(header12)\n",
        "header13 = 'No. of Columns in Street Repairs File: ' + str(f\"{df2.shape[1]:,}\")\n",
        "print(header13)\n",
        "log_txt.append(header13)\n",
        "\n",
        "header14 = ' ' \n",
        "print(header14)\n",
        "log_txt.append(header14)\n",
        "\n",
        "streets_id = df2.filter(like='_id').columns\n",
        "if df2[oci_id].columns.any():\n",
        "  df2_print = df2[streets_id].nunique().apply(lambda x : \"{:,}\".format(x))\n",
        "  df2_print = pd.DataFrame(df2_print)\n",
        "  df2_print.reset_index(inplace=True)\n",
        "  df2_print = df2_print.rename(columns={0:'Distinct Count',\n",
        "                                          'index':'ID Columns'})\n",
        "  df2_tab = tabulate(df2_print, headers = 'keys', tablefmt = 'psql')\n",
        "  print(df2_tab)\n",
        "  log_txt.append(df2_tab)\n",
        "else:\n",
        "  df2_notab= 'Street Repairs IDs DO NOT exist.'\n",
        "  print(df2_notab)\n",
        "  log_txt.append(df2_notab)\n",
        "\n",
        "header15 = ' '\n",
        "print(header15)\n",
        "log_txt.append(header15)\n",
        "\n",
        "# shape of Traffic Volumes File\n",
        "header16 = 'Traffic Volumes'\n",
        "print(header16)\n",
        "log_txt.append(header16)\n",
        "header17 = 'No. of Rows in Traffic Volumes File: ' + str(f\"{df3.shape[0]:,}\")\n",
        "print(header17)\n",
        "log_txt.append(header17)\n",
        "header18 = 'No. of Columns in Traffic Volumes File: ' + str(f\"{df3.shape[1]:,}\")\n",
        "print(header18)\n",
        "log_txt.append(header18)\n",
        "\n",
        "header19 = ' '\n",
        "print(header19)\n",
        "log_txt.append(header19)\n",
        "\n",
        "traffic_id = df3.filter(like='_id').columns\n",
        "if df3[traffic_id].columns.any():\n",
        "  df3_print = df3[traffic_id].nunique().apply(lambda x : \"{:,}\".format(x))\n",
        "  df3_print = pd.DataFrame(df3_print)\n",
        "  df3_print.reset_index(inplace=True)\n",
        "  df3_print = df3_print.rename(columns={0:'Distinct Count',\n",
        "                                        'index':'ID Columns'})\n",
        "  df3_tab = tabulate(df3_print, headers = 'keys', tablefmt = 'psql')\n",
        "  print(df3_tab)\n",
        "  log_txt.append(df3_tab)\n",
        "else:\n",
        "  df3_notab = 'Traffic Volume IDs DO NOT exist.'\n",
        "  print(df3_notab)\n",
        "  log_txt.append(df3_notab)\n",
        "\n",
        "header20 = ' '\n",
        "print(header20)\n",
        "log_txt.append(header20)\n",
        "\n",
        "###########################\n",
        "### Cross-file matching ###\n",
        "###########################\n",
        "\n",
        "df1_df2 = set(df1.columns).intersection(set(df2.columns))\n",
        "df1_df2 = list(df1_df2)\n",
        "if len(df1_df2) != 0:\n",
        "  df1_df2 = pd.DataFrame(df1_df2)\n",
        "  df1_df2 = df1_df2.rename(columns={0:'Shared Columns Between Street Repairs'\n",
        "                                    +' and OCI File'})\n",
        "  df1_df2_tab = (tabulate(df1_df2, headers = 'keys', tablefmt = 'psql'))\n",
        "  print(df1_df2_tab)\n",
        "  log_txt.append(df1_df2_tab)\n",
        "else:\n",
        "  df1_df2_notab = 'There are no shared columns between Street Repairs file' + \\\n",
        "                  ' and OCI file.'\n",
        "  print(df1_df2_notab)                \n",
        "  log_txt.append(df1_df2_notab)\n",
        "\n",
        "header21 = ' '\n",
        "print(header21)\n",
        "log_txt.append(header21)\n",
        "\n",
        "# matching `pve_id` in dataframes\n",
        "header22 = 'Matching Pve_IDs Across Files'\n",
        "print(header22)\n",
        "log_txt.append(header22)\n",
        "for name, dataframe in zip(names, dataframes):\n",
        "  if 'pve_id' in dataframe:\n",
        "    pve_id = name + ': pve_id' + ' = ' + str(True)\n",
        "    print(pve_id)\n",
        "    log_txt.append(pve_id)\n",
        "  else:\n",
        "    no_pve_id = name + ': pve_id' + ' = ' + str(False)\n",
        "    print(no_pve_id)\n",
        "    log_txt.append(no_pve_id)\n",
        "\n",
        "header23 = ' '\n",
        "print(header23)\n",
        "log_txt.append(header23)\n",
        "\n",
        "for name, dataframe in zip(names, dataframes):\n",
        "  if 'pve_id' in dataframe:\n",
        "    pve_id_exists = 'There are '+str(f\"\"\"{(dataframe['pve_id'].isin(dataframe \n",
        "                                         ['pve_id']).astype(int).value_counts() \n",
        "                                         [1]):,}\"\"\")+' '+name+ \\\n",
        "                    ' pve_ids in Streets OCI.'\n",
        "    print(pve_id_exists)                \n",
        "    log_txt.append(pve_id_exists)\n",
        "  else: \n",
        "    no_pve_id = 'There are no '+name+ ' pve_ids '+ \\\n",
        "    'in Streets OCI.'\n",
        "    print(no_pve_id)\n",
        "    log_txt.append(no_pve_id)\n",
        "\n",
        "header24 = ' '\n",
        "print(header24)\n",
        "log_txt.append(header24)\n",
        "\n",
        "# matching `seg_id` in dataframes\n",
        "\n",
        "header25 = 'Matching Seg_IDs Across Files'\n",
        "print(header25)\n",
        "log_txt.append(header25)\n",
        "\n",
        "for name, dataframe in zip(names, dataframes):\n",
        "# check for `seg_ids` in dataframes\n",
        "  if 'seg_id' in dataframe:\n",
        "    seg_log = name + ': seg_id' + ' = '+ str(True)\n",
        "    print(seg_log)\n",
        "    log_txt.append(seg_log)\n",
        "    seg_log_summary = 'There are ' + str(f\"{dataframe['seg_id'].nunique():,}\")\\\n",
        "    + ' unique seg_id values in ' + name + '.'\n",
        "    print(seg_log_summary)\n",
        "    log_txt.append(seg_log_summary)\n",
        "  else:\n",
        "    no_seg_log = name + ': seg_id' + ' = '+ str(False)\n",
        "    print(no_seg_log)\n",
        "    log_txt.append(no_seg_log)\n",
        "\n",
        "header26 = ' '\n",
        "print(header26)\n",
        "log_txt.append(header26)\n",
        "\n",
        "for name, dataframe in zip(names, dataframes):\n",
        "  if 'seg_id' in dataframe:\n",
        "    seg_id_exists = 'There are '+str(f\"\"\"{(dataframe['seg_id'].isin(dataframe\n",
        "                                         ['seg_id']).astype(int).value_counts()\n",
        "                                         [1]):,}\"\"\")+' '+name+ \\\n",
        "                    ' seg_ids in Street OCI.'\n",
        "    print(seg_id_exists)\n",
        "    log_txt.append(seg_id_exists)\n",
        "  else: \n",
        "    no_seg_id = 'There are no '+name+' seg_ids '+ \\\n",
        "    'in Streets OCI.'\n",
        "    print(no_seg_id)\n",
        "    log_txt.append(no_seg_id)\n",
        "\n",
        "report = pd.DataFrame({'San Diego Street Conditions Classification Report'\n",
        "                        :log_txt})\n",
        "\n",
        "# save report to .txt file\n",
        "report.to_csv('/drive/My Drive/san_diego_street_conditions/report.txt', \n",
        "              index=False, sep=\"\\t\",\n",
        "              quoting=csv.QUOTE_NONE,  quotechar='', escapechar='`')\n",
        "\n",
        "# save report to .rtf file\n",
        "report.to_csv('/drive/My Drive/san_diego_street_conditions/report.rtf', \n",
        "              index=False, sep=\"\\t\",\n",
        "              quoting=csv.QUOTE_NONE,  quotechar='', escapechar='`')\n"
      ],
      "metadata": {
        "id": "F4iSv1hRcxsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1740a8ea-1fa3-4859-a4aa-875466e3295d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Merged File\n",
            "No. of Rows in Merged File: 22,998\n",
            "No. of Columns in Merged File: 15\n",
            " \n",
            "Streets Overall Condition Index (OCI)\n",
            "No. of Rows in OCI File: 30,712\n",
            "No. of Columns in OCI File: 12\n",
            " \n",
            "+----+--------------+------------------+\n",
            "|    | ID Columns   | Distinct Count   |\n",
            "|----+--------------+------------------|\n",
            "|  0 | seg_id       | 30,712           |\n",
            "+----+--------------+------------------+\n",
            " \n",
            "Street Repair Projects\n",
            "No. of Rows in Street Repairs File: 23,433\n",
            "No. of Columns in Street Repairs File: 19\n",
            " \n",
            "+----+--------------+------------------+\n",
            "|    | ID Columns   | Distinct Count   |\n",
            "|----+--------------+------------------|\n",
            "|  0 | pve_id       | 23,433           |\n",
            "|  1 | seg_id       | 18,072           |\n",
            "|  2 | project_id   | 103              |\n",
            "+----+--------------+------------------+\n",
            " \n",
            "Traffic Volumes\n",
            "No. of Rows in Traffic Volumes File: 12,390\n",
            "No. of Columns in Traffic Volumes File: 10\n",
            " \n",
            "Traffic Volume IDs DO NOT exist.\n",
            " \n",
            "+----+------------------------------------------------------+\n",
            "|    | Shared Columns Between Street Repairs and OCI File   |\n",
            "|----+------------------------------------------------------|\n",
            "|  0 | street_from                                          |\n",
            "|  1 | street_to                                            |\n",
            "|  2 | seg_id                                               |\n",
            "+----+------------------------------------------------------+\n",
            " \n",
            "Matching Pve_IDs Across Files\n",
            "Streets OCI: pve_id = False\n",
            "Street Repair Projects: pve_id = True\n",
            "Traffic Volumes: pve_id = False\n",
            "Merged Dataframe: pve_id = False\n",
            " \n",
            "There are no Streets OCI pve_ids in Streets OCI.\n",
            "There are 23,433 Street Repair Projects pve_ids in Streets OCI.\n",
            "There are no Traffic Volumes pve_ids in Streets OCI.\n",
            "There are no Merged Dataframe pve_ids in Streets OCI.\n",
            " \n",
            "Matching Seg_IDs Across Files\n",
            "Streets OCI: seg_id = True\n",
            "There are 30,712 unique seg_id values in Streets OCI.\n",
            "Street Repair Projects: seg_id = True\n",
            "There are 18,072 unique seg_id values in Street Repair Projects.\n",
            "Traffic Volumes: seg_id = False\n",
            "Merged Dataframe: seg_id = False\n",
            " \n",
            "There are 30,712 Streets OCI seg_ids in Street OCI.\n",
            "There are 23,433 Street Repair Projects seg_ids in Street OCI.\n",
            "There are no Traffic Volumes seg_ids in Streets OCI.\n",
            "There are no Merged Dataframe seg_ids in Streets OCI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html /content/sd_streets_ids.ipynb"
      ],
      "metadata": {
        "id": "Qo4g9FJHi1OY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}